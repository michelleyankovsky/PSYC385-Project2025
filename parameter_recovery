import numpy as np
import pandas as pd
from scipy.stats import truncnorm
from scipy.optimize import minimize

def get_truncated_normal(mean, std, lower, upper):
    a, b = (lower - mean) / std, (upper - mean) / std
    return truncnorm.rvs(a, b, loc=mean, scale=std)

def prospect_theory_value(p, V, alpha, beta):
    weighted_probability = p ** (1 - beta)
    subjective_value = weighted_probability * (V ** alpha)
    return subjective_value

def choice_probability(delta_sv, mu):
    return 1 / (1 + np.exp(-mu * delta_sv))


def run_simulation(alpha, beta, mu, trials, sim_num):
    probability_risky_options = [0.5, 0.9]
    reward_risky_options = np.linspace(0.25, 4.0, 1000)
    reward_certain = 1

    data = {
        "Simulation": [],
        "Alpha_True": [],
        "Beta_True": [],
        "Mu_True": [],
        "Trial": [],
        "Probability_Risky": [],
        "Reward_Risky": [],
        "SV_Risky": [],
        "SV_Certain": [],
        "Delta_SV": [],
        "P_Risky": [],
        "Choice": [],
        "Reward_Certain": []
    }

    for trial in range(trials):
        probability_risky = np.random.choice(probability_risky_options)
        reward_risky = np.random.choice(reward_risky_options)

        sv_risky = prospect_theory_value(probability_risky, reward_risky, alpha, beta)
        sv_certain = reward_certain ** alpha

        delta_sv = sv_risky - sv_certain
        p_risky = choice_probability(delta_sv, mu)
        choice = 1 if np.random.rand() < p_risky else 0

        data["Simulation"].append(sim_num)
        data["Alpha_True"].append(alpha)
        data["Beta_True"].append(beta)
        data["Mu_True"].append(mu)
        data["Trial"].append(trial + 1)
        data["Probability_Risky"].append(probability_risky)
        data["Reward_Risky"].append(reward_risky)
        data["Reward_Certain"].append(reward_certain)
        data["SV_Risky"].append(sv_risky)
        data["SV_Certain"].append(sv_certain)
        data["Delta_SV"].append(delta_sv)
        data["P_Risky"].append(p_risky)
        data["Choice"].append(choice)

    return pd.DataFrame(data)

def neg_log_likelihood(params, data):
    alpha, beta, mu = params

    sv_risky = prospect_theory_value(data["Probability_Risky"], data["Reward_Risky"], alpha, beta)
    sv_certain = data["Reward_Certain"] ** alpha
    delta_sv = sv_risky - sv_certain
    p_risky = choice_probability(delta_sv, mu)

    p_risky = np.clip(p_risky, 1e-6, 1 - 1e-6)
    log_likelihood = []
    for choice, p in zip(data["Choice"], p_risky):
        if choice == 1:
            # probability of choosing risky option
            log_likelihood.append(np.log(p))
        else:
            # probability of choosing certain option
            log_likelihood.append(np.log(1 - p))
    log_likelihood = np.array(log_likelihood)

    return -np.sum(log_likelihood)

def fit_model(sim_data):
    initial_guess = [0.5, 0.3, 5.0]
    bounds = [(0.01, 2.0), (0.0, 1.0), (0.01, 20.0)]
    result = minimize(neg_log_likelihood, initial_guess, args=(sim_data,), bounds=bounds)

    if result.success:
        return result.x  # alpha, beta, mu
    else:
        print("Fitting failed:", result.message)
        return [np.nan, np.nan, np.nan]

# Simulate one participant
alpha_true = get_truncated_normal(0.65, 0.33, 0.05, np.inf)
beta_true = get_truncated_normal(0.30, 0.24, 0, 1)
mu_true = get_truncated_normal(6.77, 3.01, 0.05, np.inf)

sim_data = run_simulation(alpha_true, beta_true, mu_true, trials=1000, sim_num=1)
# fit model to simulated data
fitted_alpha, fitted_beta, fitted_mu = fit_model(sim_data)

print("\n--- True Parameters ---")
print(f"Alpha: {alpha_true:.4f}, Beta: {beta_true:.4f}, Mu: {mu_true:.4f}")

print("\n--- Fitted Parameters ---")
print(f"Alpha: {fitted_alpha:.4f}, Beta: {fitted_beta:.4f}, Mu: {fitted_mu:.4f}")
